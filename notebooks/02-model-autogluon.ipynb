{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset,TabularPredictor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1: No EDA at all, just the results of AutoGluon, best quality, default models minus KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240913_125001\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.12.3\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:30 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       12.73 GB / 32.00 GB (39.8%)\n",
      "Disk Space Avail:   374.38 GB / 460.43 GB (81.3%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.35.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"AutogluonModels/ag-20240913_125001/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240913_125001/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    167584\n",
      "Train Data Columns: 12\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13288.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 92.35 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['engine']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 116\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t('object', [])       : 8 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('object', ['text']) : 1 | ['engine']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['engine']\n",
      "\t\t('int', [])                         :  3 | ['id', 'model_year', 'milage']\n",
      "\t\t('int', ['binned', 'text_special']) : 11 | ['engine.char_count', 'engine.word_count', 'engine.capital_ratio', 'engine.lower_ratio', 'engine.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  1 | ['clean_title']\n",
      "\t\t('int', ['text_ngram'])             : 63 | ['__nlp__.0hp', '__nlp__.0hp 0l', '__nlp__.0hp 0l cylinder', '__nlp__.0hp 0l straight', '__nlp__.0hp 0l v6', ...]\n",
      "\t5.3s = Fit runtime\n",
      "\t12 features in original data used to generate 86 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 27.81 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.41s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 596.04s of the 894.28s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.35.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` \n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-73332.5258\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.02s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 586.83s of the 885.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-73655.3912\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.84s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 578.66s of the 876.9s of remaining time.\n",
      "\t-77531.0047\t = Validation score   (-root_mean_squared_error)\n",
      "\t79.11s\t = Training   runtime\n",
      "\t5.33s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 493.93s of the 792.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-73214.739\t = Validation score   (-root_mean_squared_error)\n",
      "\t171.0s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 322.53s of the 620.76s of remaining time.\n",
      "\t-76560.9421\t = Validation score   (-root_mean_squared_error)\n",
      "\t48.67s\t = Training   runtime\n",
      "\t4.99s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 268.54s of the 566.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\t-73587.6794\t = Validation score   (-root_mean_squared_error)\n",
      "\t225.78s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 41.65s of the 339.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-74078.3098\t = Validation score   (-root_mean_squared_error)\n",
      "\t39.87s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1.22s of the 299.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 0.12s of the 298.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's rmse: 86992.2\n",
      "\tTime limit exceeded... Skipping LightGBMLarge_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 297.73s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.44, 'NeuralNetFastAI_BAG_L1': 0.28, 'LightGBMXT_BAG_L1': 0.12, 'ExtraTreesMSE_BAG_L1': 0.08, 'LightGBM_BAG_L1': 0.04, 'RandomForestMSE_BAG_L1': 0.04}\n",
      "\t-73008.0199\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 297.6s of the 297.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-73086.7691\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.13s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 290.08s of the 290.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-73491.0417\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.83s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 282.88s of the 282.84s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 250 due to low time. Expected time usage reduced from 338.1s -> 282.9s...\n",
      "\t-75081.2003\t = Validation score   (-root_mean_squared_error)\n",
      "\t157.23s\t = Training   runtime\n",
      "\t4.75s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 120.6s of the 120.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-72970.6362\t = Validation score   (-root_mean_squared_error)\n",
      "\t51.52s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 68.74s of the 68.7s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 226 due to low time. Expected time usage reduced from 91.2s -> 68.7s...\n",
      "\t-74567.5598\t = Validation score   (-root_mean_squared_error)\n",
      "\t48.18s\t = Training   runtime\n",
      "\t3.94s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 16.34s of the 16.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 15.72s of the 15.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-74649.4135\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.87s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -0.06s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.52, 'LightGBMXT_BAG_L2': 0.16, 'NeuralNetFastAI_BAG_L1': 0.12, 'CatBoost_BAG_L1': 0.08, 'ExtraTreesMSE_BAG_L1': 0.04, 'RandomForestMSE_BAG_L2': 0.04, 'ExtraTreesMSE_BAG_L2': 0.04}\n",
      "\t-72938.3053\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 899.91s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 4907.8 rows/s (20948 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240913_125001/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout     score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L3  -69510.296301 -72938.305330  root_mean_squared_error        4.393935      20.897135  844.460104                 0.001599                0.001060           0.123312            3       True         15\n",
      "1          CatBoost_BAG_L2  -69515.458521 -72970.636243  root_mean_squared_error        3.459757      12.067156  631.801788                 0.097221                0.093207          51.520112            2       True         12\n",
      "2      WeightedEnsemble_L2  -69629.807960 -73008.019862  root_mean_squared_error        2.778216      11.593217  540.530225                 0.002325                0.002711           0.114776            2       True          8\n",
      "3        LightGBMXT_BAG_L2  -69661.717904 -73086.769087  root_mean_squared_error        3.520387      12.119742  587.411323                 0.157850                0.145794           7.129647            2       True          9\n",
      "4   NeuralNetFastAI_BAG_L1  -69796.764042 -73587.679426  root_mean_squared_error        1.353239       0.806660  225.780450                 1.353239                0.806660         225.780450            1       True          6\n",
      "5        LightGBMXT_BAG_L1  -69840.008117 -73332.525824  root_mean_squared_error        0.211931       0.174176    8.017005                 0.211931                0.174176           8.017005            1       True          1\n",
      "6          CatBoost_BAG_L1  -69849.951301 -73214.739041  root_mean_squared_error        0.205984       0.166796  170.997348                 0.205984                0.166796         170.997348            1       True          4\n",
      "7          LightGBM_BAG_L2  -69858.884521 -73491.041651  root_mean_squared_error        3.497146      12.089811  587.116048                 0.134609                0.115862           6.834372            2       True         10\n",
      "8          LightGBM_BAG_L1  -70088.692617 -73655.391186  root_mean_squared_error        0.148037       0.122699    7.844805                 0.148037                0.122699           7.844805            1       True          2\n",
      "9     ExtraTreesMSE_BAG_L2  -70430.432013 -74567.559836  root_mean_squared_error        3.715760      15.911300  628.458080                 0.353224                3.937351          48.176404            2       True         13\n",
      "10  RandomForestMSE_BAG_L2  -70524.444161 -75081.200267  root_mean_squared_error        3.784042      16.719723  737.510629                 0.421505                4.745775         157.228953            2       True         11\n",
      "11          XGBoost_BAG_L1  -70709.557459 -74078.309812  root_mean_squared_error        0.586646       0.383443   39.866227                 0.586646                0.383443          39.866227            1       True          7\n",
      "12          XGBoost_BAG_L2  -71302.904088 -74649.413535  root_mean_squared_error        3.895507      12.424216  595.148889                 0.532970                0.450267          14.867213            2       True         14\n",
      "13    ExtraTreesMSE_BAG_L1  -73084.915637 -76560.942090  root_mean_squared_error        0.451431       4.994994   48.669008                 0.451431                4.994994          48.669008            1       True          5\n",
      "14  RandomForestMSE_BAG_L1  -73435.802690 -77531.004684  root_mean_squared_error        0.405268       5.325180   79.106833                 0.405268                5.325180          79.106833            1       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t906s\t = DyStack   runtime |\t2694s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2694s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240913_125001\"\n",
      "Train Data Rows:    188533\n",
      "Train Data Columns: 12\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14239.80 MB\n",
      "\tTrain Data (Original)  Memory Usage: 103.94 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['engine']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 116\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 116 to 60 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t('object', [])       : 8 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('object', ['text']) : 1 | ['engine']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['engine']\n",
      "\t\t('int', [])                         :  3 | ['id', 'model_year', 'milage']\n",
      "\t\t('int', ['binned', 'text_special']) : 11 | ['engine.char_count', 'engine.word_count', 'engine.capital_ratio', 'engine.lower_ratio', 'engine.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  1 | ['clean_title']\n",
      "\t\t('int', ['text_ngram'])             : 46 | ['__nlp__.0hp', '__nlp__.0hp 0l', '__nlp__.0hp 0l cylinder', '__nlp__.0hp 0l straight', '__nlp__.0hp 0l v6', ...]\n",
      "\t5.7s = Fit runtime\n",
      "\t12 features in original data used to generate 69 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 25.18 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.75s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1791.91s of the 2688.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-72930.4108\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.59s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1782.89s of the 2679.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-73143.6558\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.81s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1774.69s of the 2671.31s of remaining time.\n",
      "\t-76920.4826\t = Validation score   (-root_mean_squared_error)\n",
      "\t77.88s\t = Training   runtime\n",
      "\t5.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1691.31s of the 2587.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-72791.1103\t = Validation score   (-root_mean_squared_error)\n",
      "\t188.64s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1502.24s of the 2398.86s of remaining time.\n",
      "\t-76053.5446\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.66s\t = Training   runtime\n",
      "\t4.95s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1453.33s of the 2349.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 0: early stopping\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "No improvement since epoch 3: early stopping\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "No improvement since epoch 0: early stopping\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "No improvement since epoch 0: early stopping\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "No improvement since epoch 0: early stopping\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 5)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 208.97s of the 1105.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-73607.498\t = Validation score   (-root_mean_squared_error)\n",
      "\t116.27s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 92.01s of the 988.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 5)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 10)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\t-73811.7313\t = Validation score   (-root_mean_squared_error)\n",
      "\t86.98s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4.33s of the 900.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 8. Best iteration is:\n",
      "\t[8]\tvalid_set's rmse: 66491.2\n",
      "\tTime limit exceeded... Skipping LightGBMLarge_BAG_L1.\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 3.57s of the 900.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tRan out of time, early stopping on iteration 8.\n",
      "\tRan out of time, early stopping on iteration 8.\n",
      "\tRan out of time, early stopping on iteration 10.\n",
      "\tRan out of time, early stopping on iteration 10.\n",
      "\tRan out of time, early stopping on iteration 11.\n",
      "\tRan out of time, early stopping on iteration 12.\n",
      "\t-75838.3144\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 0.04s of the 896.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 895.93s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.526, 'LightGBM_BAG_L1': 0.211, 'LightGBMXT_BAG_L1': 0.105, 'RandomForestMSE_BAG_L1': 0.053, 'ExtraTreesMSE_BAG_L1': 0.053, 'NeuralNetTorch_BAG_L1': 0.053}\n",
      "\t-72628.5449\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 895.8s of the 895.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-72709.5852\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.75s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 886.64s of the 886.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-73106.9528\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.08s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 878.16s of the 878.12s of remaining time.\n",
      "\t-74405.996\t = Validation score   (-root_mean_squared_error)\n",
      "\t207.19s\t = Training   runtime\n",
      "\t5.93s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 664.69s of the 664.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-72584.2906\t = Validation score   (-root_mean_squared_error)\n",
      "\t64.12s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 600.19s of the 600.15s of remaining time.\n",
      "\t-73895.7382\t = Validation score   (-root_mean_squared_error)\n",
      "\t59.14s\t = Training   runtime\n",
      "\t5.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 535.36s of the 535.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "/Users/timsteeno/Projects/used_car_prices_kaggle_s4e9/.venv/lib/python3.12/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -501.2s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.522, 'CatBoost_BAG_L1': 0.13, 'LightGBMXT_BAG_L2': 0.13, 'LightGBM_BAG_L1': 0.087, 'ExtraTreesMSE_BAG_L2': 0.087, 'RandomForestMSE_BAG_L2': 0.043}\n",
      "\t-72547.0525\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3195.63s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 5101.6 rows/s (23567 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240913_125001\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                     model     score_val              eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L3 -72547.052524  root_mean_squared_error      23.378502  872.397947                0.002354           0.118850            3       True         15\n",
      "1          CatBoost_BAG_L2 -72584.290602  root_mean_squared_error      11.944000  597.202826                0.101494          64.124807            2       True         13\n",
      "2      WeightedEnsemble_L2 -72628.544877  root_mean_squared_error      11.300469  413.667747                0.001728           0.113331            2       True          9\n",
      "3        LightGBMXT_BAG_L2 -72709.585151  root_mean_squared_error      11.981141  541.825100                0.138634           8.747081            2       True         10\n",
      "4          CatBoost_BAG_L1 -72791.110291  root_mean_squared_error       0.179091  188.637105                0.179091         188.637105            1       True          4\n",
      "5        LightGBMXT_BAG_L1 -72930.410777  root_mean_squared_error       0.231901    8.591110                0.231901           8.591110            1       True          1\n",
      "6          LightGBM_BAG_L2 -73106.952751  root_mean_squared_error      11.954015  541.159719                0.111508           8.081700            2       True         11\n",
      "7          LightGBM_BAG_L1 -73143.655841  root_mean_squared_error       0.167854    7.811786                0.167854           7.811786            1       True          2\n",
      "8           XGBoost_BAG_L1 -73607.498004  root_mean_squared_error       0.466915  116.269846                0.466915         116.269846            1       True          6\n",
      "9    NeuralNetTorch_BAG_L1 -73811.731281  root_mean_squared_error       0.576876   86.975295                0.576876          86.975295            1       True          7\n",
      "10    ExtraTreesMSE_BAG_L2 -73895.738151  root_mean_squared_error      17.202158  592.216352                5.359652          59.138333            2       True         14\n",
      "11  RandomForestMSE_BAG_L2 -74405.996048  root_mean_squared_error      17.776367  740.268877                5.933861         207.190858            2       True         12\n",
      "12    CatBoost_r177_BAG_L1 -75838.314360  root_mean_squared_error       0.076850    3.253757                0.076850           3.253757            1       True          8\n",
      "13    ExtraTreesMSE_BAG_L1 -76053.544580  root_mean_squared_error       4.952778   43.661367                4.952778          43.661367            1       True          5\n",
      "14  RandomForestMSE_BAG_L1 -76920.482576  root_mean_squared_error       5.190240   77.877754                5.190240          77.877754            1       True          3\n",
      "Number of models trained: 15\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XT', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])                    :  7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "('category', ['text_as_category'])  :  1 | ['engine']\n",
      "('int', [])                         :  3 | ['id', 'model_year', 'milage']\n",
      "('int', ['binned', 'text_special']) : 11 | ['engine.char_count', 'engine.word_count', 'engine.capital_ratio', 'engine.lower_ratio', 'engine.digit_ratio', ...]\n",
      "('int', ['bool'])                   :  1 | ['clean_title']\n",
      "('int', ['text_ngram'])             : 46 | ['__nlp__.0hp', '__nlp__.0hp 0l', '__nlp__.0hp 0l cylinder', '__nlp__.0hp 0l straight', '__nlp__.0hp 0l v6', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20240913_125001SummaryOfModels.html\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT', 'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost', 'NeuralNetTorch_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch', 'CatBoost_r177_BAG_L1': 'StackerEnsembleModel_CatBoost', 'WeightedEnsemble_L2': 'WeightedEnsembleModel', 'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L2': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost', 'ExtraTreesMSE_BAG_L2': 'StackerEnsembleModel_XT', 'WeightedEnsemble_L3': 'WeightedEnsembleModel'}, 'model_performance': {'LightGBMXT_BAG_L1': -72930.41077656059, 'LightGBM_BAG_L1': -73143.65584058811, 'RandomForestMSE_BAG_L1': -76920.48257627193, 'CatBoost_BAG_L1': -72791.11029055351, 'ExtraTreesMSE_BAG_L1': -76053.5445795376, 'XGBoost_BAG_L1': -73607.4980041165, 'NeuralNetTorch_BAG_L1': -73811.7312813013, 'CatBoost_r177_BAG_L1': -75838.31435960867, 'WeightedEnsemble_L2': -72628.54487694513, 'LightGBMXT_BAG_L2': -72709.58515123684, 'LightGBM_BAG_L2': -73106.95275121255, 'RandomForestMSE_BAG_L2': -74405.99604755816, 'CatBoost_BAG_L2': -72584.29060187802, 'ExtraTreesMSE_BAG_L2': -73895.73815086734, 'WeightedEnsemble_L3': -72547.05252372747}, 'model_best': 'WeightedEnsemble_L3', 'model_paths': {'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'], 'LightGBM_BAG_L1': ['LightGBM_BAG_L1'], 'RandomForestMSE_BAG_L1': ['RandomForestMSE_BAG_L1'], 'CatBoost_BAG_L1': ['CatBoost_BAG_L1'], 'ExtraTreesMSE_BAG_L1': ['ExtraTreesMSE_BAG_L1'], 'XGBoost_BAG_L1': ['XGBoost_BAG_L1'], 'NeuralNetTorch_BAG_L1': ['NeuralNetTorch_BAG_L1'], 'CatBoost_r177_BAG_L1': ['CatBoost_r177_BAG_L1'], 'WeightedEnsemble_L2': ['WeightedEnsemble_L2'], 'LightGBMXT_BAG_L2': ['LightGBMXT_BAG_L2'], 'LightGBM_BAG_L2': ['LightGBM_BAG_L2'], 'RandomForestMSE_BAG_L2': ['RandomForestMSE_BAG_L2'], 'CatBoost_BAG_L2': ['CatBoost_BAG_L2'], 'ExtraTreesMSE_BAG_L2': ['ExtraTreesMSE_BAG_L2'], 'WeightedEnsemble_L3': ['WeightedEnsemble_L3']}, 'model_fit_times': {'LightGBMXT_BAG_L1': 8.59110975265503, 'LightGBM_BAG_L1': 7.811785936355591, 'RandomForestMSE_BAG_L1': 77.87775421142578, 'CatBoost_BAG_L1': 188.637104511261, 'ExtraTreesMSE_BAG_L1': 43.66136693954468, 'XGBoost_BAG_L1': 116.26984643936157, 'NeuralNetTorch_BAG_L1': 86.97529482841492, 'CatBoost_r177_BAG_L1': 3.2537567615509033, 'WeightedEnsemble_L2': 0.11333084106445312, 'LightGBMXT_BAG_L2': 8.747080564498901, 'LightGBM_BAG_L2': 8.081699848175049, 'RandomForestMSE_BAG_L2': 207.19085788726807, 'CatBoost_BAG_L2': 64.12480664253235, 'ExtraTreesMSE_BAG_L2': 59.13833284378052, 'WeightedEnsemble_L3': 0.1188499927520752}, 'model_pred_times': {'LightGBMXT_BAG_L1': 0.2319014072418213, 'LightGBM_BAG_L1': 0.16785383224487305, 'RandomForestMSE_BAG_L1': 5.190240144729614, 'CatBoost_BAG_L1': 0.1790914535522461, 'ExtraTreesMSE_BAG_L1': 4.952777862548828, 'XGBoost_BAG_L1': 0.4669148921966553, 'NeuralNetTorch_BAG_L1': 0.5768764019012451, 'CatBoost_r177_BAG_L1': 0.07685041427612305, 'WeightedEnsemble_L2': 0.001728057861328125, 'LightGBMXT_BAG_L2': 0.13863444328308105, 'LightGBM_BAG_L2': 0.11150836944580078, 'RandomForestMSE_BAG_L2': 5.933861017227173, 'CatBoost_BAG_L2': 0.10149383544921875, 'ExtraTreesMSE_BAG_L2': 5.359652042388916, 'WeightedEnsemble_L3': 0.0023539066314697266}, 'num_bag_folds': 8, 'max_stack_level': 3, 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'XGBoost_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'NeuralNetTorch_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'CatBoost_r177_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMXT_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'ExtraTreesMSE_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'WeightedEnsemble_L3': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                      model     score_val              eval_metric  \\\n",
      "0      WeightedEnsemble_L3 -72547.052524  root_mean_squared_error   \n",
      "1          CatBoost_BAG_L2 -72584.290602  root_mean_squared_error   \n",
      "2      WeightedEnsemble_L2 -72628.544877  root_mean_squared_error   \n",
      "3        LightGBMXT_BAG_L2 -72709.585151  root_mean_squared_error   \n",
      "4          CatBoost_BAG_L1 -72791.110291  root_mean_squared_error   \n",
      "5        LightGBMXT_BAG_L1 -72930.410777  root_mean_squared_error   \n",
      "6          LightGBM_BAG_L2 -73106.952751  root_mean_squared_error   \n",
      "7          LightGBM_BAG_L1 -73143.655841  root_mean_squared_error   \n",
      "8           XGBoost_BAG_L1 -73607.498004  root_mean_squared_error   \n",
      "9    NeuralNetTorch_BAG_L1 -73811.731281  root_mean_squared_error   \n",
      "10    ExtraTreesMSE_BAG_L2 -73895.738151  root_mean_squared_error   \n",
      "11  RandomForestMSE_BAG_L2 -74405.996048  root_mean_squared_error   \n",
      "12    CatBoost_r177_BAG_L1 -75838.314360  root_mean_squared_error   \n",
      "13    ExtraTreesMSE_BAG_L1 -76053.544580  root_mean_squared_error   \n",
      "14  RandomForestMSE_BAG_L1 -76920.482576  root_mean_squared_error   \n",
      "\n",
      "    pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
      "0       23.378502  872.397947                0.002354           0.118850   \n",
      "1       11.944000  597.202826                0.101494          64.124807   \n",
      "2       11.300469  413.667747                0.001728           0.113331   \n",
      "3       11.981141  541.825100                0.138634           8.747081   \n",
      "4        0.179091  188.637105                0.179091         188.637105   \n",
      "5        0.231901    8.591110                0.231901           8.591110   \n",
      "6       11.954015  541.159719                0.111508           8.081700   \n",
      "7        0.167854    7.811786                0.167854           7.811786   \n",
      "8        0.466915  116.269846                0.466915         116.269846   \n",
      "9        0.576876   86.975295                0.576876          86.975295   \n",
      "10      17.202158  592.216352                5.359652          59.138333   \n",
      "11      17.776367  740.268877                5.933861         207.190858   \n",
      "12       0.076850    3.253757                0.076850           3.253757   \n",
      "13       4.952778   43.661367                4.952778          43.661367   \n",
      "14       5.190240   77.877754                5.190240          77.877754   \n",
      "\n",
      "    stack_level  can_infer  fit_order  \n",
      "0             3       True         15  \n",
      "1             2       True         13  \n",
      "2             2       True          9  \n",
      "3             2       True         10  \n",
      "4             1       True          4  \n",
      "5             1       True          1  \n",
      "6             2       True         11  \n",
      "7             1       True          2  \n",
      "8             1       True          6  \n",
      "9             1       True          7  \n",
      "10            2       True         14  \n",
      "11            2       True         12  \n",
      "12            1       True          8  \n",
      "13            1       True          5  \n",
      "14            1       True          3  }\n"
     ]
    }
   ],
   "source": [
    "train_data = TabularDataset('../data/raw/train.csv')\n",
    "test_data = TabularDataset('../data/raw/test.csv')\n",
    "\n",
    "predictor = TabularPredictor(label='price', eval_metric='rmse', problem_type='regression').fit(\n",
    "    train_data,\n",
    "    presets='best_quality',\n",
    "    verbosity=2,\n",
    "    excluded_model_types=['KNN'],\n",
    "    ag_args_fit={'num_cpus': 8}\n",
    ")\n",
    "\n",
    "results = predictor.fit_summary()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>...</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>compile_time</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-29418.371474</td>\n",
       "      <td>-76920.482576</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.477539</td>\n",
       "      <td>5.190240</td>\n",
       "      <td>77.877754</td>\n",
       "      <td>1.477539</td>\n",
       "      <td>5.190240</td>\n",
       "      <td>77.877754</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-29923.251792</td>\n",
       "      <td>-76053.544580</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.395628</td>\n",
       "      <td>4.952778</td>\n",
       "      <td>43.661367</td>\n",
       "      <td>1.395628</td>\n",
       "      <td>4.952778</td>\n",
       "      <td>43.661367</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-65406.196661</td>\n",
       "      <td>-73895.738151</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>16.725206</td>\n",
       "      <td>17.202158</td>\n",
       "      <td>592.216352</td>\n",
       "      <td>1.431365</td>\n",
       "      <td>5.359652</td>\n",
       "      <td>59.138333</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-66166.622879</td>\n",
       "      <td>-72628.544877</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>11.800025</td>\n",
       "      <td>11.300469</td>\n",
       "      <td>413.667747</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.113331</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, RandomForestMSE_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ensemble_size': 25, 'subsample_size': 1000000}</td>\n",
       "      <td>{'ensemble_size': 19}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, RandomForestMSE_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-66540.091411</td>\n",
       "      <td>-74405.996048</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>16.894074</td>\n",
       "      <td>17.776367</td>\n",
       "      <td>740.268877</td>\n",
       "      <td>1.600233</td>\n",
       "      <td>5.933861</td>\n",
       "      <td>207.190858</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-68171.079399</td>\n",
       "      <td>-73607.498004</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>3.382169</td>\n",
       "      <td>0.466915</td>\n",
       "      <td>116.269846</td>\n",
       "      <td>3.382169</td>\n",
       "      <td>0.466915</td>\n",
       "      <td>116.269846</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}</td>\n",
       "      <td>{'n_estimators': 44}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-68181.700447</td>\n",
       "      <td>-73143.655841</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.285090</td>\n",
       "      <td>0.167854</td>\n",
       "      <td>7.811786</td>\n",
       "      <td>1.285090</td>\n",
       "      <td>0.167854</td>\n",
       "      <td>7.811786</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05}</td>\n",
       "      <td>{'num_boost_round': 62}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-69117.664929</td>\n",
       "      <td>-72547.052524</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>19.687063</td>\n",
       "      <td>23.378502</td>\n",
       "      <td>872.397947</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.118850</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[LightGBM_BAG_L1, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, RandomForestMSE_BAG_L2, CatBoost_BAG_L1, CatBoost_BAG_L2]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'ensemble_size': 25, 'subsample_size': 1000000}</td>\n",
       "      <td>{'ensemble_size': 23}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L2, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, CatBoost_BAG_L2, LightGBMXT_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-69597.891488</td>\n",
       "      <td>-72584.290602</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>15.665959</td>\n",
       "      <td>11.944000</td>\n",
       "      <td>597.202826</td>\n",
       "      <td>0.372118</td>\n",
       "      <td>0.101494</td>\n",
       "      <td>64.124807</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}</td>\n",
       "      <td>{'iterations': 133}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-70225.845367</td>\n",
       "      <td>-73106.952751</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>16.094961</td>\n",
       "      <td>11.954015</td>\n",
       "      <td>541.159719</td>\n",
       "      <td>0.801120</td>\n",
       "      <td>0.111508</td>\n",
       "      <td>8.081700</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05}</td>\n",
       "      <td>{'num_boost_round': 44}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-70327.939305</td>\n",
       "      <td>-72709.585151</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>16.279673</td>\n",
       "      <td>11.981141</td>\n",
       "      <td>541.825100</td>\n",
       "      <td>0.985832</td>\n",
       "      <td>0.138634</td>\n",
       "      <td>8.747081</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05, 'extra_trees': True}</td>\n",
       "      <td>{'num_boost_round': 56}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-70641.128124</td>\n",
       "      <td>-72930.410777</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.800495</td>\n",
       "      <td>0.231901</td>\n",
       "      <td>8.591110</td>\n",
       "      <td>1.800495</td>\n",
       "      <td>0.231901</td>\n",
       "      <td>8.591110</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'learning_rate': 0.05, 'extra_trees': True}</td>\n",
       "      <td>{'num_boost_round': 84}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-71837.352858</td>\n",
       "      <td>-72791.110291</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.861162</td>\n",
       "      <td>0.179091</td>\n",
       "      <td>188.637105</td>\n",
       "      <td>0.861162</td>\n",
       "      <td>0.179091</td>\n",
       "      <td>188.637105</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}</td>\n",
       "      <td>{'iterations': 486}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-73618.161851</td>\n",
       "      <td>-73811.731281</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>4.974057</td>\n",
       "      <td>0.576876</td>\n",
       "      <td>86.975295</td>\n",
       "      <td>4.974057</td>\n",
       "      <td>0.576876</td>\n",
       "      <td>86.975295</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[engine.symbol_ratio.., clean_title, ext_col, engine.symbol_count./, engine.digit_ratio, int_col, accident, engine.char_count, milage, engine.symbol_count.., engine.capital_ratio, engine.lower_ratio, engine.special_ratio, engine.symbol_ratio./, brand, engine.word_count, fuel_type, model, model_year, engine.symbol_ratio. , transmission, id]</td>\n",
       "      <td>None</td>\n",
       "      <td>{'num_epochs': 500, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}</td>\n",
       "      <td>{'batch_size': 256, 'num_epochs': 5}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CatBoost_r177_BAG_L1</td>\n",
       "      <td>-75645.944088</td>\n",
       "      <td>-75838.314360</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.117701</td>\n",
       "      <td>0.076850</td>\n",
       "      <td>3.253757</td>\n",
       "      <td>0.117701</td>\n",
       "      <td>0.076850</td>\n",
       "      <td>3.253757</td>\n",
       "      <td>...</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}</td>\n",
       "      <td>[__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'iterations': 10000, 'learning_rate': 0.06864209415792857, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'max_ctr_complexity': 4, 'one_hot_max_size': 10}</td>\n",
       "      <td>{'iterations': 8}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model    score_test     score_val  \\\n",
       "0   RandomForestMSE_BAG_L1 -29418.371474 -76920.482576   \n",
       "1     ExtraTreesMSE_BAG_L1 -29923.251792 -76053.544580   \n",
       "2     ExtraTreesMSE_BAG_L2 -65406.196661 -73895.738151   \n",
       "3      WeightedEnsemble_L2 -66166.622879 -72628.544877   \n",
       "4   RandomForestMSE_BAG_L2 -66540.091411 -74405.996048   \n",
       "5           XGBoost_BAG_L1 -68171.079399 -73607.498004   \n",
       "6          LightGBM_BAG_L1 -68181.700447 -73143.655841   \n",
       "7      WeightedEnsemble_L3 -69117.664929 -72547.052524   \n",
       "8          CatBoost_BAG_L2 -69597.891488 -72584.290602   \n",
       "9          LightGBM_BAG_L2 -70225.845367 -73106.952751   \n",
       "10       LightGBMXT_BAG_L2 -70327.939305 -72709.585151   \n",
       "11       LightGBMXT_BAG_L1 -70641.128124 -72930.410777   \n",
       "12         CatBoost_BAG_L1 -71837.352858 -72791.110291   \n",
       "13   NeuralNetTorch_BAG_L1 -73618.161851 -73811.731281   \n",
       "14    CatBoost_r177_BAG_L1 -75645.944088 -75838.314360   \n",
       "\n",
       "                eval_metric  pred_time_test  pred_time_val    fit_time  \\\n",
       "0   root_mean_squared_error        1.477539       5.190240   77.877754   \n",
       "1   root_mean_squared_error        1.395628       4.952778   43.661367   \n",
       "2   root_mean_squared_error       16.725206      17.202158  592.216352   \n",
       "3   root_mean_squared_error       11.800025      11.300469  413.667747   \n",
       "4   root_mean_squared_error       16.894074      17.776367  740.268877   \n",
       "5   root_mean_squared_error        3.382169       0.466915  116.269846   \n",
       "6   root_mean_squared_error        1.285090       0.167854    7.811786   \n",
       "7   root_mean_squared_error       19.687063      23.378502  872.397947   \n",
       "8   root_mean_squared_error       15.665959      11.944000  597.202826   \n",
       "9   root_mean_squared_error       16.094961      11.954015  541.159719   \n",
       "10  root_mean_squared_error       16.279673      11.981141  541.825100   \n",
       "11  root_mean_squared_error        1.800495       0.231901    8.591110   \n",
       "12  root_mean_squared_error        0.861162       0.179091  188.637105   \n",
       "13  root_mean_squared_error        4.974057       0.576876   86.975295   \n",
       "14  root_mean_squared_error        0.117701       0.076850    3.253757   \n",
       "\n",
       "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  ...  \\\n",
       "0                  1.477539                5.190240          77.877754  ...   \n",
       "1                  1.395628                4.952778          43.661367  ...   \n",
       "2                  1.431365                5.359652          59.138333  ...   \n",
       "3                  0.006054                0.001728           0.113331  ...   \n",
       "4                  1.600233                5.933861         207.190858  ...   \n",
       "5                  3.382169                0.466915         116.269846  ...   \n",
       "6                  1.285090                0.167854           7.811786  ...   \n",
       "7                  0.003674                0.002354           0.118850  ...   \n",
       "8                  0.372118                0.101494          64.124807  ...   \n",
       "9                  0.801120                0.111508           8.081700  ...   \n",
       "10                 0.985832                0.138634           8.747081  ...   \n",
       "11                 1.800495                0.231901           8.591110  ...   \n",
       "12                 0.861162                0.179091         188.637105  ...   \n",
       "13                 4.974057                0.576876          86.975295  ...   \n",
       "14                 0.117701                0.076850           3.253757  ...   \n",
       "\n",
       "                                                                                                                     hyperparameters  \\\n",
       "0   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}   \n",
       "1   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}   \n",
       "2   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}   \n",
       "3                         {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "4   {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}   \n",
       "5                          {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "6                          {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "7                         {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "8                          {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "9                          {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "10                         {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "11                         {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "12                         {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "13                         {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "14                         {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}   \n",
       "\n",
       "    hyperparameters_fit  \\\n",
       "0                    {}   \n",
       "1                    {}   \n",
       "2                    {}   \n",
       "3                    {}   \n",
       "4                    {}   \n",
       "5                    {}   \n",
       "6                    {}   \n",
       "7                    {}   \n",
       "8                    {}   \n",
       "9                    {}   \n",
       "10                   {}   \n",
       "11                   {}   \n",
       "12                   {}   \n",
       "13                   {}   \n",
       "14                   {}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                            ag_args_fit  \\\n",
       "0   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "1   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "2   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "3   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "4   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "5   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "6   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "7   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "8   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "9   {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "10  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "11  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "12  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "13  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "14  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   features  \\\n",
       "0   [__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...   \n",
       "1   [__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...   \n",
       "2   [__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, RandomForestMSE_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]   \n",
       "4   [__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...   \n",
       "5   [__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...   \n",
       "6   [__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [LightGBM_BAG_L1, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, RandomForestMSE_BAG_L2, CatBoost_BAG_L1, CatBoost_BAG_L2]   \n",
       "8   [__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...   \n",
       "9   [__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...   \n",
       "10  [__nlp__.engine gasoline, __nlp__.v6 cylinder, ExtraTreesMSE_BAG_L1, milage, engine.capital_ratio, __nlp__.v6, __nlp__.dohc, __nlp__.gdi, __nlp__.0hp 7l cylinder, __nlp__.0hp 7l, __nlp__.8l, __nlp__.0hp 5l, __nlp__.0hp 4l cylinder, engine, __nlp__.7l cylinder, __nlp__.3l, __nlp__.electric, __nlp__.2l, clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__._total_, __nlp__.0hp 0l straight, __nlp__.0hp 5l v6, __nlp__.0hp 0l, __nlp__.cylinder, engine.special_ratio, CatBoost_BAG_L1, engine.symbol_ratio./, __nlp__.0hp 6l, __nlp__.engine, model_year, __nlp__.0hp 2l cylinder, NeuralNetTorch_BAG_L...   \n",
       "11  [__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...   \n",
       "12  [__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...   \n",
       "13                                                                                                                                                                                                                                                                    [engine.symbol_ratio.., clean_title, ext_col, engine.symbol_count./, engine.digit_ratio, int_col, accident, engine.char_count, milage, engine.symbol_count.., engine.capital_ratio, engine.lower_ratio, engine.special_ratio, engine.symbol_ratio./, brand, engine.word_count, fuel_type, model, model_year, engine.symbol_ratio. , transmission, id]   \n",
       "14  [__nlp__.engine gasoline, __nlp__.2l, engine.symbol_ratio.., clean_title, __nlp__.7l, ext_col, __nlp__.16v, __nlp__.v6 cylinder, __nlp__.5l, __nlp__.6l v6, engine.symbol_count./, engine.digit_ratio, __nlp__._total_, int_col, accident, engine.char_count, __nlp__.0hp 0l straight, __nlp__.0hp 2l, __nlp__.fuel, milage, engine.symbol_count.., __nlp__.0hp 5l v6, __nlp__.cylinder engine, __nlp__.0hp 0l, engine.capital_ratio, __nlp__.cylinder, __nlp__.3l, engine.lower_ratio, engine.special_ratio, __nlp__.v6, __nlp__.4l, engine.symbol_ratio./, brand, engine.word_count, __nlp__.0hp 4l, __nlp__.dohc,...   \n",
       "\n",
       "    compile_time  \\\n",
       "0           None   \n",
       "1           None   \n",
       "2           None   \n",
       "3           None   \n",
       "4           None   \n",
       "5           None   \n",
       "6           None   \n",
       "7           None   \n",
       "8           None   \n",
       "9           None   \n",
       "10          None   \n",
       "11          None   \n",
       "12          None   \n",
       "13          None   \n",
       "14          None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              child_hyperparameters  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                  {'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                  {'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                  {'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'ensemble_size': 25, 'subsample_size': 1000000}   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                  {'n_estimators': 300, 'max_leaf_nodes': 15000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'learning_rate': 0.05}   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  {'ensemble_size': 25, 'subsample_size': 1000000}   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                               {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'learning_rate': 0.05}   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     {'learning_rate': 0.05, 'extra_trees': True}   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     {'learning_rate': 0.05, 'extra_trees': True}   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                              {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}   \n",
       "13  {'num_epochs': 500, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}   \n",
       "14                                                                                                                                                                                                                                                                                               {'iterations': 10000, 'learning_rate': 0.06864209415792857, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'max_ctr_complexity': 4, 'one_hot_max_size': 10}   \n",
       "\n",
       "               child_hyperparameters_fit  \\\n",
       "0                  {'n_estimators': 300}   \n",
       "1                  {'n_estimators': 300}   \n",
       "2                  {'n_estimators': 300}   \n",
       "3                  {'ensemble_size': 19}   \n",
       "4                  {'n_estimators': 300}   \n",
       "5                   {'n_estimators': 44}   \n",
       "6                {'num_boost_round': 62}   \n",
       "7                  {'ensemble_size': 23}   \n",
       "8                    {'iterations': 133}   \n",
       "9                {'num_boost_round': 44}   \n",
       "10               {'num_boost_round': 56}   \n",
       "11               {'num_boost_round': 84}   \n",
       "12                   {'iterations': 486}   \n",
       "13  {'batch_size': 256, 'num_epochs': 5}   \n",
       "14                     {'iterations': 8}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                             child_ag_args_fit  \\\n",
       "0                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "1                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "2                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "3                                                          {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "4                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "5                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "6                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "7                                                          {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}   \n",
       "8                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "9                                 {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "10                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "11                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "12                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "13  {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': ['text_ngram', 'text_as_category'], 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "14                                {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 8}   \n",
       "\n",
       "                                                                                                                                                                                                                                             ancestors  \\\n",
       "0                                                                                                                                                                                                                                                   []   \n",
       "1                                                                                                                                                                                                                                                   []   \n",
       "2                                                                                     [ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]   \n",
       "3                                                                                                                           [ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, RandomForestMSE_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]   \n",
       "4                                                                                     [ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]   \n",
       "5                                                                                                                                                                                                                                                   []   \n",
       "6                                                                                                                                                                                                                                                   []   \n",
       "7   [ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L2, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, CatBoost_BAG_L2, LightGBMXT_BAG_L1]   \n",
       "8                                                                                     [ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]   \n",
       "9                                                                                     [ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]   \n",
       "10                                                                                    [ExtraTreesMSE_BAG_L1, LightGBM_BAG_L1, NeuralNetTorch_BAG_L1, CatBoost_r177_BAG_L1, RandomForestMSE_BAG_L1, XGBoost_BAG_L1, CatBoost_BAG_L1, LightGBMXT_BAG_L1]   \n",
       "11                                                                                                                                                                                                                                                  []   \n",
       "12                                                                                                                                                                                                                                                  []   \n",
       "13                                                                                                                                                                                                                                                  []   \n",
       "14                                                                                                                                                                                                                                                  []   \n",
       "\n",
       "                                                                                                                                      descendants  \n",
       "0   [WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]  \n",
       "1   [WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]  \n",
       "2                                                                                                                           [WeightedEnsemble_L3]  \n",
       "3                                                                                                                                              []  \n",
       "4                                                                                                                           [WeightedEnsemble_L3]  \n",
       "5                        [WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]  \n",
       "6   [WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]  \n",
       "7                                                                                                                                              []  \n",
       "8                                                                                                                           [WeightedEnsemble_L3]  \n",
       "9                                                                                                                                              []  \n",
       "10                                                                                                                          [WeightedEnsemble_L3]  \n",
       "11  [WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]  \n",
       "12  [WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]  \n",
       "13  [WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, WeightedEnsemble_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]  \n",
       "14                       [WeightedEnsemble_L3, LightGBMXT_BAG_L2, ExtraTreesMSE_BAG_L2, RandomForestMSE_BAG_L2, LightGBM_BAG_L2, CatBoost_BAG_L2]  \n",
       "\n",
       "[15 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(train_data, extra_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 12 features using 5000 rows with 5 shuffle sets...\n",
      "\t149.46s\t= Expected runtime (29.89s per shuffle set)\n",
      "\t57.01s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>milage</th>\n",
       "      <td>5135.079576</td>\n",
       "      <td>893.524082</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>5</td>\n",
       "      <td>6974.858011</td>\n",
       "      <td>3295.301141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine</th>\n",
       "      <td>3972.176394</td>\n",
       "      <td>909.660213</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>5</td>\n",
       "      <td>5845.179345</td>\n",
       "      <td>2099.173443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_year</th>\n",
       "      <td>2028.005660</td>\n",
       "      <td>370.624742</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>5</td>\n",
       "      <td>2791.127127</td>\n",
       "      <td>1264.884194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>1393.779774</td>\n",
       "      <td>644.424942</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>5</td>\n",
       "      <td>2720.659637</td>\n",
       "      <td>66.899911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>916.653939</td>\n",
       "      <td>220.080971</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>5</td>\n",
       "      <td>1369.803700</td>\n",
       "      <td>463.504178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ext_col</th>\n",
       "      <td>593.580830</td>\n",
       "      <td>238.071722</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>5</td>\n",
       "      <td>1083.773797</td>\n",
       "      <td>103.387863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>575.153300</td>\n",
       "      <td>154.527776</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>5</td>\n",
       "      <td>893.328127</td>\n",
       "      <td>256.978473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmission</th>\n",
       "      <td>559.481354</td>\n",
       "      <td>76.058364</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>5</td>\n",
       "      <td>716.086576</td>\n",
       "      <td>402.876132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_col</th>\n",
       "      <td>369.761431</td>\n",
       "      <td>219.021413</td>\n",
       "      <td>0.009760</td>\n",
       "      <td>5</td>\n",
       "      <td>820.729548</td>\n",
       "      <td>-81.206686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accident</th>\n",
       "      <td>276.414774</td>\n",
       "      <td>123.893248</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>5</td>\n",
       "      <td>531.512684</td>\n",
       "      <td>21.316864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_title</th>\n",
       "      <td>103.804796</td>\n",
       "      <td>45.151271</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>5</td>\n",
       "      <td>196.771886</td>\n",
       "      <td>10.837705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuel_type</th>\n",
       "      <td>68.736106</td>\n",
       "      <td>51.551642</td>\n",
       "      <td>0.020340</td>\n",
       "      <td>5</td>\n",
       "      <td>174.881651</td>\n",
       "      <td>-37.409438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               importance      stddev   p_value  n     p99_high      p99_low\n",
       "milage        5135.079576  893.524082  0.000106  5  6974.858011  3295.301141\n",
       "engine        3972.176394  909.660213  0.000308  5  5845.179345  2099.173443\n",
       "model_year    2028.005660  370.624742  0.000128  5  2791.127127  1264.884194\n",
       "model         1393.779774  644.424942  0.004212  5  2720.659637    66.899911\n",
       "brand          916.653939  220.080971  0.000370  5  1369.803700   463.504178\n",
       "ext_col        593.580830  238.071722  0.002537  5  1083.773797   103.387863\n",
       "id             575.153300  154.527776  0.000569  5   893.328127   256.978473\n",
       "transmission   559.481354   76.058364  0.000040  5   716.086576   402.876132\n",
       "int_col        369.761431  219.021413  0.009760  5   820.729548   -81.206686\n",
       "accident       276.414774  123.893248  0.003775  5   531.512684    21.316864\n",
       "clean_title    103.804796   45.151271  0.003394  5   196.771886    10.837705\n",
       "fuel_type       68.736106   51.551642  0.020340  5   174.881651   -37.409438"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125690, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "#y_proba = predictor.predict_proba(test_data)\n",
    "\n",
    "submission = pd.DataFrame({'id': test_data['id'], 'price': y_pred})\n",
    "print(submission.shape)\n",
    "submission.to_csv('submissions/submission_20240913_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 1.99M/1.99M [00:00<00:00, 4.64MB/s]\n",
      "Successfully submitted to Regression of Used Car Prices"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s4e9 -f submission_20240913_01.csv -m \"Raw AutoGluon:best-practices run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
